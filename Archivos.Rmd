---
title: "Ciencia de Datos y R"
subtitle: "Introducción a la Ciencia de Datos con Lenguaje R"
author: "Ariel E. Meilij"
date: "`r Sys.Date()`"
output: tint::tintHtml
bibliography: skeleton.bib
link-citations: no
---

```{r setup, include=FALSE}
library(tint)
# invalidate cache when the package version changes
knitr::opts_chunk$set(tidy = FALSE, cache.extra = packageVersion('tint'))
options(htmltools.dir.version = FALSE)
```

# ARCHIVOS EN R

## Introducción a los Archivos de Datos en R
`r tint::newthought('La ciencia de datos se basa muchas veces en el análisis de datos que alguien más investigó')`. Hay varias ramas de la ciencia de datos. Una parte importante de estos científicos trabajan en las empresas de Internet (desde Facebook y Swiftkey hasta Etsy pasando por Basecamp) analizando datos de producción: clics en botones, preferencias de uso y compra, perfil de consumidores, predicción de gustos, etc. Otra parte de los científicos de datos fungen como analistas de negocios (muy comúnmente en Wall Street llamados _quants_) revisando el comportamiento de los mercados, y tratando de predecir el movimiento de elementos bursátiles como acciones y bonos. Finalmente, un tercer grupo se dedica a las ciencias naturales como Bioestadistas ayudando a validar los estudios de investigación de químicos, ingenieros, físicos, etc.

Las fuentes de datos son múltiples. Hemos vistos juegos de datos cuidadosamente curados que cargamos en la memoria de R con la función `data()`. Otros archivos pueden leerse desde disco, como los archivos planos cuyos campos vienen separados por comas (conocidos como *.csv o _comma separated value_) o aquellos que se leen desde una base de datos como MySQL o Postgres. También hay datos que se pueden leer directamente desde Internet: una descarga de archivos en línea o leer en línea los contenidos de un sitio web para descubrir patrones dentro del código.

Las fuentes de datos son múltiples, y si bien no son infinitas, son muchas. En este texto vamos a cubrir las más básicas de ellas, suficiente como para comenzar a trabajar y avanzar en el lenguaje *R* cómodamente.

* juegos de datos empaquetados
* archivos planos
* archivos de fuentes en el Internet
* archivos de MySQL
* archivos de Excel

También veremos lo fácil que es leer campos en un archivo y volver a escribirlo al disco duro en caso de ser necesario.

## Introducción a la Data
Antes de seguir hablando de _data_, definamos primero lo que queremos decir cuando usamos el término.

### Definición de Data
_Data_: La _data_ son valores de variables cualitativas o cuantitativas que pertenecen a un conjunto de entes [@pengMatsui].

Cuando hablamos de un conjunto de entes, hablamos de cualquier población o muestra del cual surge la data, como por ejemplo la población de una ciudad, la muestra de clics de un sitio web en un día lunes, o el peso promedio de niños nacidos de embarazos prematuros en un año en particular, dividido por sexo, región, nivel sociodemográfico, y peso al nacer. 

* Cualitativo: son aquellas variables de valor no-numérico como país, sexo, tipo de tratamiento, etc.

* Cuantitativo: son aquellas variables de valor númerico como altura, peso, presión arterial, etc. 

Para propósitos generales, un científico de datos manipula dos tipos de data: cruda y procesada. 

### Distinción entre Data Cruda y Procesada
De la misma forma que hemos definido el concepto de data, establezcamos una definición clara entre data cruda y procesada.

* La data cruda es la fuente original de los datos, la cual es complicada de utilizar en el análisis. Comúnmente la data cruda necesita procesamiento para aplicarse de forma sencilla al análisis, y este procesamiento se debe hacer solo una vez. 

* La data procesada es la data que está lista para el análisis. El procesamiento incluye tareas como unir, agregar y transformar datos. Pudiera ser que este procesamiento tiene estándares establecidos (como por ejemplo reglas contables, procesos de laboratorio requeridos por ley, reglas de imputación, etc.) Todos los pasos en el procesamiento de datos deben registrarse ya que la ciencia de datos es una ciencia que descansa sobre el método científico. 

La data cruda existe en formatos que pueden variar de los sencillos (archivos planos) hasta los complejos (archivos binarios). Un análisis puede cubrir la unión y referencia cruzada de una hoja de cálculos con 10 pestañas, y un archivo JSON de un API de Twitter. En caso particulares hasta puede incluir notas a mano de un científico que está describiendo un fenómeno en su microscopio. 

La data cruda se encuentra en el formato correcto para procesamiento si se dan las siguientes condiciones [@leek]:

1. No se ha procesado la data aún con ningún tipo de software (esta condición no incluye el software que generó la data)
2. No se ha manipulado los números de la data de ninguna manera
3. No se ha removido ningún elemento de la data
4. No se ha resumido la data en ninguna manera

### Componentes de Data Limpia (Tidy Data)
La idea detrás del procesamiento de datos es pasar de data cruda a data limpia (en inglés _tidy data_) a través de un proceso con cuatro elementos muy concretos. 

i. La data cruda
ii. La data limpia (tidy data)
iii. Un libro de código donde se detalle de forma explícita cada variable y su valor correspondiente en el juego de datos limpio (tidy data)
iv. Una receta explícita y detallada de como se procesó y transformó cada variable

```{marginfigure}
Algunos autores se refieren al libro de código como meta-data.
```

El concepto de data limpia no es sinónimo de data procesada, aunque los dos están estrechamente ligados. Por data limpia (tidy data) queremos decir que los datos cumplen cuatro condiciones específicas.

1. Cada variable de medición debe estar en una columna de la base de datos o juego de datos
2. Cada observación diferente de esa variable debiera estar en su propia fila
3. Debe existir una tabla o juego de datos para cada tipo de variable
4. Para juegos de datos con múltiples tablas, debe existir una columna como índice común de tabulación cruzada

Fuera de la teoría y ya entrando en _R_, hay maneras de comenzar a aplicar estos preceptos en el código.

* Incluir en los _data frame_ una fila inicial donde se incluyan los nombres de las variables (fácil de decir pero curiosamente difícil de cumplir al momento del estudio)

* Hacer los nombres de las variables humanamente legibles

* Guardar la data en una tabla por archivo - aunque ocupe un poco más de espacio

### El Libro de Código
El libro de código es un paso obligado en la ciencia de datos, que se apega al método científico de registrar todo lo concerniente a la investigación en curso con ánimo de dar total transparencia a la metodología y reproducción de la investigación. En su definición, un Libro de Código describe los contenidos, estructura y diseño de una colección de data. Un libro de código bien documentado contiene información cuya intención es ser completa y auto-explanatoria para cada nivel de la data en un archivo de datos del juego estudiado [@codebook].

Los libros de código debieran empezar con una sección de introducción que incluya el título de la investigación, el nombre de los científicos de datos, la tabla de contenidos y una reseña que describa el propósito y formato del manual. Algunos libros también incluyen detalles de la metodología utilizada, como el cálculo de los pesos estadísticos, los instrumentos de recolección de datos, y otros datos importante para la reproducción de los experimentos según y de acuerdo con la complejidad de los mismos y los datos involucrados [@codebook]. 

El cuerpo principal del libro de código utiliza descripción y detalles específicos y no ambiguos de las variables en cada nivel de la estructura de datos. El siguiente ejemplo es del estudio National Longitudinal Survey of Youth, 1979 .

![](images/codebook-01.png)

*Nombre de la Variable:* El nombro o número asignado a la variable en cada colección de datos. Alguno investigadores prefieren utilizar abrevaciones mnemotécnicas (ejemplo LABOR2) mientras que otros utiizan patrones alfanuméricos (ejemplo, VARI009). Una práctica común en los estudios de encuesta es nombrar las variables con el orden correspondiente de las preguntas (ejemplo PREG001). 

*Etiqueta de la Variable:* Una descripción breve pero completa que identifica la variable al lector y usuario. Cuando sea posible conviene utilizar la construcción completa de la pregunta que generó la variable (ejemplo: TRM001 - valor de la tasa de referencia de mercado del dólar USA en el sistema bancario de Colombia). 

*Contenido de la Pregunta:* Por lo general se utiliza en las encuestas solamente, y es la pregunta que debe/debió hacerse para generar el contenido de la variable (por ejemplo: "Si las elecciones fueran hoy, ¿a cuáles de estos tres candidatos Usted votaría?). Puede omitirse en estudios de laboratorio seco o de recolección en campo a menos que ayude a aclarar dudas sobre el origen de la variable.

*Texto de la Pregunta:* Solamente aplica a encuestas y a diferencia del contenido es la oración exacta que se utilizó en la encuesta frente al encuestado.

*Valores:* Los valores actuales codificados en la data. Estos pueden ser una colección de valores específicos unidos a una tabla finita de valores ordinales (ejemplo 1,2,3) o cotas de valores discretos cuando aplique (ejemplo: medición de la humedad relativa del ambiente del 0 al 100 por ciento).

*Etiqueta de los Valores:* La descripción textual de los valores utilizados en la codificación de valores ordinales (por ejemplo Excelente, Bueno, Malo). En caso de que los valores sean discretos igualmente se puede etiquetar las cotas, lo que ayuda a señalar cuáles valores se considerarán valores estadísticos átipicos (outliers). 

*Resumen de Estadísticas:* Donde sea apropiado, y dependiendo del estilo del estudio y características de la variable, proveer un resumen (sin pesos ni normalización) estadístico de la misma para referencia rápida. Para variables categóricas se puede incluir las frecuencias de valores que ocurren y sus porcentajes asociados. Para variables continuas es recomendable utilizar minímos, máximos, promedios y medianas, algo que _R_ provee con el comando `summary()`. 

*Datos Faltantes:* Donde aplique es importante resaltar los valores y etiquetas de data faltante (ejemplos, valores NA en una lista). La ausencia de datos puede alterar o sesgar un análisis por lo tanto se hace vital explicar las medidas de imputación de datos. Recuerde describir todos los valoresy códigos asumidos para la ausencia de datos. 

*Patrones de Salto del Universo:* Los patrones de salto se presentan mucho en las encuestras, donde el encuestado puede no querer/poder responder una pregunta y el encuestador puede tener un proceso establecido de que pregunta saltar en caso de una omisión, ya sea intencional o no intencional. Dada la importancia de los patrones de salto en los estudios sociales, deben no solo registrarse, sino hacer omisión a la variable que los precede y la variable siguiente en el salto (ejemplo: próxima pregunta si el encuestado no contesta PREG010). 

*Notas:* Notas adicionales, comentarios o consejos que contextualizan la información que cubre la variable o despliegan contenido adicional. Esta sección también es la indicada para adicionar mediciones y/o preguntas de instrumentos con licencias o patentes de marca especiales.

El profesor Jeffrey Leek de John Hopkins University comparte algunas recomendaciones académicas para la confección del libro de código.

* Siempre incluir no solo las variables sino todas las unidades asociadas de medición, extensivo para cada elemento del juego de datos. Aunque no aplica para valores ordinales, es cierto para valores reales y continuos donde no es necesariamente autoevidente en que escala se mide (ejemplo: temperatura Celsius versus Fahrenheit). 

* Agregar un resumen de las decisiones que se tomaron en el estudio y diseño de la metodología de recolección de datos y las razones para tales decisiones. En el futuro otro investigador puede encontrar fallas o procesos alternativos para volver a implementar el estudio con nuevos resultados. 

* Siempre agregar información sobre el diseño del estudio en si que complemente el diseño de la metodología de recolección de datos. 

Una sección en la que toca Leek a diferencia de otros autores es la Lista de Instrucción [@leek]. La lista de instrucción es el _script_ generado en el código de trabajo que procesa la data. La lista de instucción funciona mucho mejor cuando el ingreso y egreso son auto-evidentes y no hay mayor parametrización de los datos. Esto no siempre es posible y algunos estudios requieren manipulación adicional del procesamiento que no se puede cubrir en un simple listado de _R_ o _Python_. En tales casos es preferible incluir la descripción total del proceso aunque manual a omitirlo.Un ejemplo didactico es el siguiente.

1. Paso 1: tomar el archivo X y correr la versión 3.2.1 del software XX de procesamiento para resumir los datos con los parámetros a = 1, b = 2, y c = 3.
2. Paso 2: ejecutar el software para cada uno de los diez archivos posibles de muestras de manera separada con los parámetros descritos en el paso 1. 
3. Paso 3: tomar la columna 3 de cada archivo de salida por cada archivo de entrada y agregarlos en un solo archivo final de proceso en el juego de datos. 

## Cómo Leer Datos Empaquetados
Hemos estado leyendo juegos de datos empaquetados por varios capítulos, pero igual lo volvemos a describir aquí por propósitos didacticos. Utilicemos la función `data()` para cargar un juego de datos en memoria, y usemos el operador `?` para que *R* nos de datos valiosos sobre el mismo.

```
data(iris)
?iris
iris {datasets} R Documentation
Edgar Anderson's Iris Data

Description

This famous (Fisher's or Anderson's) iris data set gives the measurements in centimeters of the variables sepal length and width and petal length and width, respectively, for 50 flowers from each of 3 species of iris. The species are Iris setosa, versicolor, and virginica.

Usage

iris
iris3
Format

iris is a data frame with 150 cases (rows) and 5 variables (columns) named Sepal.Length, Sepal.Width, Petal.Length, Petal.Width, and Species.

iris3 gives the same data arranged as a 3-dimensional array of size 50 by 4 by 3, as represented by S-PLUS. The first dimension gives the case number within the species subsample, the second the measurements with names Sepal L., Sepal W., Petal L., and Petal W., and the third the species.

Source

Fisher, R. A. (1936) The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7, Part II, 179–188.

The data were collected by Anderson, Edgar (1935). The irises of the Gaspe Peninsula, Bulletin of the American Iris Society, 59, 2–5.

References

Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) The New S Language. Wadsworth & Brooks/Cole. (has iris3 as iris.)

See Also

matplot some examples of which use iris.

Examples

dni3 <- dimnames(iris3)
ii <- data.frame(matrix(aperm(iris3, c(1,3,2)), ncol = 4,
                        dimnames = list(NULL, sub(" L.",".Length",
                                        sub(" W.",".Width", dni3[[2]])))),
    Species = gl(3, 50, labels = sub("S", "s", sub("V", "v", dni3[[3]]))))
all.equal(ii, iris) # TRUE
```

Como podemos ver estos juegos de datos han sido curados. Curar data es un término con un significado muy específico dentro de la ciencia, y abarca la administración de data a través de su ciclo de vida, desde la creación y su almacenaje inicial hasta el momento en el cual se archiva para la posteridad o se vuelve obsoleta y se elimina. El propósito principal de la curación de datos es asegurar que la misma sea altamente confiable para uso de investigación futura.

```{marginfigure}
De hecho los comandos `head()` y `tail()` son similares a los de línea de comandos en `bash`, usando Linux o FreeBSD.
```

Si queremos ver los primeros registros del juego de datos iris podemos utilizar el comando `head()`.

```{r ejemploHead()}
# ejemplo comando head()
head(iris, 10)
```

El valor por defecto de `head()` son los primeros seis registros, pero esto se puede variar agregando después de la coma el número de registros que nos gustaría ver. También podemos ver los últimos registros con la función `tail()`.

```{r ejemploTail()}
tail(iris, 10)
```

Si nos interesa saber la estructura de campos de un juego de datos, lo mejor es utilizar el comando `str()` que nos devuelve su estructura.

```{r ejemploStr}
str(iris)
```

Una pregunta válida es qué tipo de estructura de datos es iris. Con esto nos queremos referir como una estructura curada de datos, pero eso no nos dice mucho desde el punto de vista del lenguaje *R*. Ante la duda, es fácil utilizar la función `class()` que nos devuelve el tipo de estructura (no solo con el juego iris sino con prácticamente cualquier otra variable en uso).

```{r ejemploClass}
class(iris)
```

El juego de datos iris ha sido empaquetado como un `data.frame` y quizás esa sea una de las mejores opciones disponibles. Sin embargo, no es la única para manipular datos.

## Cómo leer archivos de texto
Hay dos métodos muy comunes de lectura de archivos de texto. El primero es leer un archivo usando la estructura de datos `read.table()`. Usemos esta forma de lectura para datos muy poco estructurados, como el que vamos a ver a continuación.

```
Estructura de nombres.txt
Juanito sobrino
Jorgito sobrino
Jaimito sobrino
Donald pariente
```
 
```{marginfigure}
Hemos de notar que `read.table()` es la función más utilizada en _R_ para leer datos (Nota del autor: por lo menos en el año que escribimos la aseveración). La función en si es robusta y flexible, pero requiere más parámetros que otras funciones. Un aspecto que debemos tener en cuentas es que la función lee todos los datos en el *RAM* del computador, por lo que puede causar problemas y poner el sistema bajo estrés si el juego de datos es grande, la memoria disponible es limitada, o una condición de los dos factores de forma simultanea. 
```

El que vemos es un archivo muy primitivo y donde nos conviene usar el poder de `read.table()` para que *R* nos devuelva una estructura ordenada.

```{r ejemploReadTable(), warning=FALSE, message=FALSE}
# veamos en que directorio estamos
getwd()

# no es donde quiero leer mis datos, cambiemos el directorio
setwd("/Users/ameilij/Documents/Publications/CDyR")

library(data.table)
nombres <- read.table("nombres.txt")
nombres

str(nombres)

for(i in 1:dim(nombres)[1]) {
  print(paste("Nombre: ", nombres[i, 1], "- Estatus: ", nombres[i, 2]))
}
```

El valor de cada columna viene sin nombre y R le asigna V1, V2… Vx. Usar este formato es cómodo para hacer búsquedas dentro de los índices.

```{r ejemploBusquedaArchivoTable, warning=FALSE, message=FALSE}
library(data.table)
nombres <- read.table("nombres.txt")
nombres[nombres$V2 == "sobrino", ]
```

No todos los formatos son tan primitivos. Uno muy común es el de archivo plano cuyos campos se separan con comas. Estos archivos son la forma más fácil de compartir información de bases de datos o hojas de cálculo como EXCEL para que todo el mundo los pueda leer. Veamos un ejemplo de estos.

```
Estructura de lotes.csv
Lote, Valor
"1AA", 100
"1AD", 90
"1AB", 100
"1AB", 80
"1AC", 50
"1AD", 85
"1AA", 90
"1AC", 200
```

Pensemos en esta estructura de lotes como el peso promedio de recolección de café y que cada canasta tiene un identificador de lote especial. Lo que queremos hacer es estudiar un poco este lote para ver los rendimientos de cada parcela.

```{r ejemploReadCSV}
lotes <- read.csv("lotes.csv", header = TRUE)
head(lotes, 3)

str(lotes)

class(lotes)
```

Noten que a pesar de ser un archivo de formato `comma separated value` ya *R* lo transformó en una estructura del tipo `data.frame`. No todos los archivos `.cvs` tienen nombres de columna. Como este los tenía le instruimos a *R* leerlos correctamente con el argumento `header = TRUE`. Veamos un poco más de la información en lotes.

```{r ejemploLOTES}
summary(lotes)
```

Bien, por lo que vemos hay cuatro lotes, del 1AA al 1AD y tres lecturas por cada uno. En total, los valores de los lotes van de 50 kilos hasta 200 kilos, pero eso no nos dice mucho sobre cada lote en particular. Veamos una gráfica de la distribución de pesos por lote.

```{r verificarLOTES}
boxplot(Valor ~ Lote, data = lotes, main = "Rendimiento de Kg/Cafe por Lote", xlab = "Lote", ylab = "Kgs.")
```

Cada rectángulo del gráfico nos da los valores promedios y rangos de cuartil de cada lote. Las líneas más pequeñas por encima y por debajo son los valores extremos de cada lote. Como pueden ver, los lotes 1AA, 1AB, y 1AD son relativamente similares, pero el lote 1AC tiene rendimientos promedios muy superiores a los demás.

## Archivos de Internet
El Internet se creo inicialmente para el intercambio de conocimiento y datos científicos. La cantidad de información disponible es impresionante, pero no solo de datos modernos como los provenientes de las redes sociales, sino juegos de datos curados para la investigación científica. Cuando uno lee un archivo, lo correcto es abrir una conexión y utilizar esa conexión para la lectura. Un ejemplo claro es el siguiente.

```{r ejemploReadWeb1}
conexion <- file("lotes.csv")
miArchivo <- read.csv(conexion)
head(miArchivo)
```

La razón por la cual no vemos mucho código de este tipo es que el lenguaje ha crecido y evolucionado y hacemos lo siguiente en vez.

```{r ejemploReadWeb2}
myArchivo <- read.csv("lotes.csv")
head(miArchivo)
```

```{marginfigure}
Los programadores son propensos a buscar la mejor forma de reducir la tarea a mano, y los de R por lo general están más interesados en la matemática del asunto que en la programación del asunto. Esto no afecta mucho la exploración de datos, pero en otros entornos dejar una conexión abierta pudiera ser inseguro por lo bajo y hasta catastrófico si la mala suerte ataca.
```

Leer un archivo de Internet no es sino abrir una conexión con un `URL` (la dirección de Internet de donde está ubicada la base de datos que nos interesa) y leer el archivo con esa conexión como si fuera cualquier otro archivo. Veamos un ejemplo de cómo leer un sitio web y descargarlo en disco duro. Al momento de escribir el siguiente libro, como medida de control de versión, ibamos guardando los diferentes borradores en *Github*. *Git* es un sistema de control de versiones: guarda el trabajo de a poco, versión a versión, para que no se vaya perdiendo los cambios que uno hace. Es mucho más útil cuando varias personas están trabajando en un proyecto y deben cooperar. *Github* es un sitio en la nube para guardar proyectos, y es muy usado por la comunidad de *R*. Cada capítulo del libro era un archivo en formato `.Rmd`, que usa `R Mark-Down` para transformar el texto en un *PDF* con forma muy pulida, similar a lo que resulta de usar Word, pero con la facilidad de ejecutar el código dentro del texto. A manera de agregado, *Github* le permite a uno tener una página web (solo una por proyecto) para documentar el proyecto, y esa es precisamente la página web que vamos a leer.

```{r ejemploLeerGithub}
setwd("~/Documents/Publications/CDyR")
ubicacionURL <- "https://ameilij.github.io/CDyR/"
download.file(ubicacionURL, destfile = "testSitioWeb.html")
```

Veamos el código línea por línea:

1. La primera línea usa la función `setwd()` que fija el directorio de trabajo. El código está editado para Mac usando OS X, pero es casi igual para Windows.
2. La segunda línea simplemente crea una variable con la dirección del sitio donde está guardada la información. Esto no es necesario, se puede utilizar la dirección directamente en el siguiente comando, pero es una buena práctica de uso ya que la dirección puede cambiar varias veces en un mes, sobre todo si es un sitio que tiene mucho movimiento o que está generado dinámicamente por algún programa adicional y los enlaces no son fijos.
3. La tercera línea usa la función `download.file()` para descargar el archivo desde una ubicación en la web (que le pasamos a través de la variable `ubicacionURL`) y lo descarga a un archivo de destino que en este caso le pasamos con una dirección que solo contiene el nombre del archivo sin ninguna ubicación de carpeta.

Lo que hemos hecho es básicamente descargar del Internet todo el código *HTML* que compone el sitio del libro y colocarlo como un archivo en nuestro disco duro. Podemos accesar a la información con la función `readLines()` ya que este no es un archivo con columnas o variables bien estructuradas, sino un archivo de texto con lineas variables llenas de tags *HTML*.

```{r ejemploReadLines}
miDocumento <- readLines("testSitioWeb.html")
miDocumento[1:5]
```

Es muy probable que en el futuro tengan que descargar un archivo de datos bien estructurado de algún sitio web científico para un análisis. Esto se puede descargar al disco duro a través del explorador (Firefox, Safari, Chrome, etc.) pero lo ideal es ya hacerlo desde *R* para que quede el código fuente registrado paso por paso. Los siguientes datos son del libro *CASE STUDIES IN BIOMETRY*, escrito por Nicholas Lange, Louise Ryan,Lynne Billard, David Brillinger, Loveday Conquest, Joel Greenhouse, (1994) de editorial Wiley. Los datos que vamos a bajar del mismo son del capítulo 11, cuyo título en inglés es *Time-Series Analyses of Beaver Body Temperatures* (Análisis de Series de Tiempo de Temperatura Corporal de Castores).

```{r ejemploFREAD}
# Cargar la función fread() con el paquete data.table
library(data.table)
datosCastores <- fread('http://www.stats.ox.ac.uk/pub/datasets/csb/ch11b.dat')
head(datosCastores)

# Guardar en el disco duro como datos en formato .txt
write.table(datosCastores, file = "datosCastores.txt")
```

Ya que tenemos este juego de datos, veamos su utilidad. ¿Cómo varía la medición de los castores y su temperatura corporal? ¿Podemos resumir el estudio en un gráfico de caja?

```{marginfigure}
En el ejemplo siguiente utilizamos la función `par(mfrow=c(1.2))` para decirle a *R* que coloque los dos gráficos en una línea de dos columnas. Es una forma conveniente de diagramar la ubicación de los gráficos.
```

```{r graficaBoxplot}
par(mfrow=c(1,2))
plot(datosCastores$V3, datosCastores$V4, main = "Muestras Temp. Corp.", 
     xlab = "muestra", ylab = "Temp.C.")
boxplot(datosCastores$V4, main = "Resumen Temp. Corp")
```
 
## Leer Archivos CSV
El formato CSV (del inglés Comma Separated Value) es común en todo tipo de entornos, quizás por su sencillez de estructura y el poco peso de sus archivos. Exportar juegos de datos a formato CSV es un método repetido y seguro de compartir información a través de múltiples plataformas, lenguajes y sistemas operativos. Si bien vimos algo de data en archivos CSV, este tipo de formato es tan común que muchas veces conviene leerlo en su estructura natural.

El lenguaje _R_ utiliza la función `read.csv()` con la siguiente sintaxis:

`read.csv(file, header = FALSE, sep = "", quote = "", na.strings = "NA")`

La cantidad de parámetros totales es mucho más grande que la que listamos aquí, pero ciertamente estos son los que se usan el 99% de los casos. 

* `file` es el nombre del archivo que deseamos utilizar, y es conveniente para mantener legibilidad del código entre plataformas de SO ponerlo entre comillas dobles. 

* `header` es una bandera (flag) que indica si la primera fila del archivo tiene o no los nombres de las variables. El valor por omisión es `FALSE` ya que generalmente este tipo de archivo es para listas sencillas de datos, pero se puede fijar a `TRUE` en caso de que el archivo que se maneje si llegara a tener una fila con los encabezamientos. 

* `sep` es el parámetro que fija el separador entre campos. Si el archivo está separado por comas, no hay ni siquiera que agregarlo, y lo contradictorio de la función es que se puede fijar para leer espacios en blanco como separadores con `sep = ""`. Esto último también acepta como separadores caracteres de tabulación y de línea nueva (ENTER).

* `quote` es el parámetro para alternar entre comillas y no comillas. Es preferible no tocarlo, pero en caso de querer obviar comillas en campos alfanuméricos se puede fijar como `quote = ""`. 

* `na.strings = "NA"` fija por omisión el valor *NA* como el de datos no disponibles. Pudiera existir la posibilidad de que algún sistema o software utilice algún otro valor o denominador y se tenga que cambiar el valor del parámetro. 

```{marginfigure}
El formato CSV también se puede leer con la función `read.table()` y es una de esas áreas donde el lenguaje _R_ solapa funciones y usos. Sin embargo `read.table()` transforma directamente a formato _data frame_, y pudieramos querer mantener el archivo como está para simplificar análisis, o redireccionar el resultado a algún programa que debe leerlo como CSV. 
```

Podemos utilizar la función `read.csv()` con el archivo `lotes.csv` como hicimos en el ejemplo de la función `read.table()`.

```{r ejemploReadCSV_2}
data_lotes <- read.csv("lotes.csv")
head(data_lotes)
```

## Leer Archivos de EXCEL
Existe una noción dentro de la Ciencia de Datos que un científico de datos debe evitar el uso de EXCEL. Inclusive dentro de la comunidad de la Ciencia de Datos, hay activistas vocales contra el uso de la hoja de cálculo. Las razones para tales aseveraciones están fundamentadas en cinco puntos principales [@smith].

```{marginfigure}
Es importante conocer las debilidades de EXCEL en cuanto a la Ciencia de Datos. Al mismo tiempo es importante reconocer que casi todas las empresas del mundo usan EXCEL porque es mucho más sencillo armar una hoja de cálculo en EXCEL que programar la misma estructura de datos en un lenguaje científico. Los autores del libro utilizan EXCEL de forma diaria y para ciertas labores no tiene reemplazo por su sencillez de uso y rapidez de despliegue de prototipos. Aquí lo importante como científicos de datos es utilizar la data que otros crearon en EXCEL, un recurso precioso, y no preocuparse por las bondades o falta de ellas de EXCEL al momento de diseñar modelos complejos de análisis estadístico.
```

1. Reproducibilidad: un análisis de ciencia de datos debe ser reproducible y si bien esto es posible en EXCEL, la herramienta no se diseño con la reproducción de experimentos en mente. 
2. Control de Versión: la hoja de cálculo tiene herramientas para registrar los cambios pero no un verdadero control de versiones, el cual solo es posible con programas como *Git* o *Subversion*.
3. Test: es difícil programar tests en EXCEL para que con cada cambio de juegos de datos se detecten errores en la programación o la experimentación. 
4. Mantenimiento: algunas investigaciones científicas pueden durar años o décadas. El mantenimiento del código de un programa privado se dificulta versus la flexibilidad de un lenguaje de programación Open Source. 
5. Precisión: EXCEL tiene precisión muy exacta para ciertos campos y disciplinas, pero no lo suficiente para la Ciencia de Datos. Un ejemplo es la falta de precisión al momento de analizar gramaticalmente formatos de fecha. 

```{marginfigure}
Los autores recomiendan la libreria `readxl` diseñada por Hadley Wickham y Jennifer Bryan, ambos del equipo de RStudio, ya que es una biblioteca independiente de otras fuentes. Existen otras opciones, pero hemos encontrado que hay muchos conflictos entre sistemas operativos y las dependencias de las mismas.  
```

No importa de que lado del campo del debate se esté la realidad es que hay millones de hojas de cálculo con información disponible en EXCEL y tarde o temprano el científico de datos tendra que leer datos de las mismas. La forma de hacer esto es utilizando la biblioteca externa _xlsx_ para leer hojas de cálculo. 

La mejor forma de hacer esto es con la libreria `readxl()`. La función funciona muy bien con muy pocos parámetros según la siguiente sintáxis:

`read_excel(file, sheet = pestaña, range = un_rango)`

donde 

* `file` es el nombre del archivo entre comillas
* `sheet =` es la forma de fijar el parámetro de pestaña a abrir de existir múltiples en una hoja de cálculo. En caso de existir múltiples pestañas pero no tener nombres (ejemplo: Sheet1, Sheet2, y sucesivo) se puede utilizar el número natural de la hoja como en `range = 2`.
* `range =` es el rango de celdas a leer dentro de la hoja y pestaña de EXCEL. Estos pueden expresarse como un rango natural (ejemplo: "A1:D10") e inclusive se puede obviar el parámetro de pestaña y especificar todo en el rango (ejemplo: "Sheet1!A1:D10").

El comando puede funcionar bien sin más que el nombre de la hoja de cálculo en el caso de que solo exista información en una sola pestaña. Es importante recordar que para manipular columnas de la hoja de datos, utilizar la nomenclatura `datos$columna`. Por ejemplo, en el script de ejemplo `mean(gastos$GASTOS)` retorna el promedio de gastos del juego de datos, pero `mean(gastos)` devuelve un error. 

```{r ejemploReadXL, warning=FALSE, message=FALSE}
library(readxl)
ventas <- read_excel("ventas.xlsx", sheet = "2017")
boxplot(ventas$VENTAS, main = 
          "Ventas por Territorio 2017")

gastos <- read_excel("ventas.xlsx", range = "2018!C1:C6")
mean(gastos$GASTOS)
```



## Leer Archivos XML
El formato XML es una forma extensible de lenguaje _mark-up_, usado muy frecuentemente para guardar datos, sobre todo en los entornos de Internet y aplicaciones relacionadas con la web [@leek]. Es importante entender el formato XML no solo por el incremento en su uso, sino porque es la base de las técnicas de _web scrapping_, o la extracción de datos de los sitios web. 

Los archivos XML tienen dos componentes. 

a. El código *mark-up* que son las etiquetas que le dan estructura
b. El contenido en si mismo

Este libro no es un manual de XML, pero en línea general existen etiquetas denominadas _tags_ que cumplen con la función de demarcar donde empiezan y terminan las estructuras. 

* _start tags_ de comienzo como `<section>` para el comienzo de una sección
* _end tags_ de final como `</section>` para el final de una sección
* _tags_ vacíos para etiquetas de comentario como `<line-break />`

Los elementos son el contenido específico de los _tags_ como por ejemplo:

`<Sexo>macho</Sexo>`

Los atributos son los componentes de la etiqueta:

`<img src="imagen.png" alt="imagen" />`

La mejor forma de leer archivos XML es con la librería externa `XML`. Esta librería utiliza la función `xmlTreeParse()` para cargar un documento XML y crear un análisis sintáctico en forma de árbol con los elementos del mismo (conocido en inglés como _parsing a file_). La segunda función es `xmlRoot()` la cual toma el objeto que analizó la función `xmlParseTree()` y lo aloja en un nuevo objeto empaquetado que se puede manipular y traversar libremente. Pensemos en `xmlRoot()` como un objeto del tipo `wrapper` al cual podemos acceder en _R_ ubicando las diferentes ramas como índices del tipo `[[1]]`.

Transversar las ramas de un archivo XML es mucho más fácil con funciones que a simple vista, ya que la estructura _mark-up_ facilita la asimilación para los lenguajes y las máquinas pero no necesariamente para los humanos. Veamos un ejemplo simple con un archivo XML hipotético de inventarios de carros como el que figura a continuación.

```
<inventario>
  <carro>
    <nombre>Sedan</nombre>
    <precio>1000</precio>
  </carro>
  <carro>
    <nombre>SUV</nombre>
    <precio>2000</precio>
  </carro>
    <carro>
    <nombre>Coupe</nombre>
    <precio>4000</precio>
  </carro>
</inventario>
```
Podemos cargar en memoria el archivo y acceder a sus componentes de la siguiente manera. 

```{r ejemploReadXML}
library(XML)
documento <- xmlTreeParse("inventario.xml", useInternal = TRUE)
DocumentoNodo <- xmlRoot(documento)

# Ver nombre del archivo maestro
xmlName(DocumentoNodo)

# Ver nombre de los contenidos
names(DocumentoNodo)

# Ver el primer auto
DocumentoNodo[[1]]

# Ver solo el precio del tercer auto
DocumentoNodo[[3]][[2]]

```

Como podemos ver las funciones son poderosas para rápidamente leer archivos XML y extraer valores y estructuras, sino fuera por el hecho de que extraemos no solo el valor, sino la etiqueta que acompaña (por ejemplo `DocumentoNodo[[3]][[2]]` retorna `<precio>4000</precio>` cuando probablemente solo queremos el valor `4000`). La librería _XML_ prevé esto y nos permite utilizar la función `xmlSApply()` para justamente solo extraer valores de los nodos de los archivos XML. La sintáxis de la función es la siguiente. 

`xmlSApply(nodoRoot, nodo, valorXML)`

donde:

* el parámetro `nodoRoot` es la variable donde se ha leído y extraído el arbol del contenido XML (incluyendo el análisis gramatical).
* el parámetro `nodo` es el tipo de nodo que queremos extraer utilizando patrones determinantes de nodos en el árbol XML
* el parámetro `xmlValue` extrae el valor del nodo especificado en el archivo `nodoRoot`

```{marginfigure}
Si el lector piensa que transversar un árbol XML parece complicado, no lo es tanto como que la sintáxis es complicada. La implementación de XML tiene sus pormenores, pero en su expresión más sencilla no dejan de ser archivos de texto con etiquetas para señalar de forma inequívoca su estructura.
```

Los patrones determinantes son opciones de expresiones que nos permiten conducir la busqueda a través de los nodos del árbol XML. Hay cuatro principales que estaremos utilizando en este texto.

| Expresión                         | Valor                                           |
|-----------------------------------|-------------------------------------------------|
| /nodo                             | Nodo Principal                                  |
| //nodo                            | Nodo en cualquier nivel                         |
| nodo[@nombre_atributo]            | Nodo con nombre del atributo                    |
| nodo[@nombre_atributo = 'Carlos'] | Nodo con nombre del atributo y valor específico |

Los siguientes ejemplos sirven para despejar dudas sobre la implemetación de búsquedas transversando un árbol XML.

```{r ejemploReadXML_2, warning=FALSE, message=FALSE}
library(XML)
documento <- xmlTreeParse("inventario.xml", useInternal = TRUE)
DocumentoNodo <- xmlRoot(documento)

# Revisar que carros hay disponibles
xpathSApply(DocumentoNodo, "//carro", xmlValue)

# Revisar que precios hay disponibles
xpathSApply(DocumentoNodo, "//precio", xmlValue)

# Revisar que carros hay disponible por precios menores a 3,000
xpathSApply(DocumentoNodo, "/inventario/carro[precio < 3000]/nombre", xmlValue)

```

Hemos de notar que en todos los ejemplos anteriores la función nos devuelve cadenas de caracteres ( _strings_ ) como respuesta. El analista quizás tenga que transformar tipos de caracteres a numérico para utilizar los valores en otro paso de la cadena de análisis. 

## Leer Archivos JSON
JSON (del inglés _JavaScript Object Notation_,  o notación de objeto de JavaScript) es un formato de texto sencillo para el intercambio de datos. Se trata de un subconjunto de la notación literal de objetos de _JavaScript_, aunque, debido a su amplia adopción como alternativa a XML, se considera un formato de lenguaje independiente.

```{marginfigure}
Si bien se tiende a considerar JSON como una alternativa a XML, lo cierto es que no es infrecuente el uso de JSON y XML en la misma aplicación; así, una aplicación de cliente que integra datos de Google Maps con datos meteorológicos en SOAP necesita hacer uso de ambos formatos.
```

Hay varias ventajas que han popularizado el uso de JSON como formato de intercambio de data.

* Es una formato de muy bajo peso
* Tiene un formato común para acumular datos en diferentes API's
* Tiene una estructura similar a XML pero con sintáxis diferente

Utilicemos como ejemplo el archivo de muestra de la página Wikipedia de JSON [@JSON].

```
{
    "menu": {
        "id": "file",
        "value": "File",
        "popup": {
            "menuitem": [
                {
                    "value": "New", "onclick": "CreateNewDoc()"
                },{
                    "value": "Open", "onclick": "OpenDoc()"
                },{
                    "value": "Close", "onclick": "CloseDoc()"
                }
            ]
        }
    }
}
```
La forma de leer archivos del tipo *JSON* es con la librería externa `jsonlite` y la función `fromJSON()`, la cual es muy fácil de utilizar simplemente pasando como parámetro el nombre del archivo que se quiere extraer. 

```{r ejemploReadJSON, warning=FALSE, message=FALSE}
library(jsonlite)
dataJSON <- fromJSON("ejemploJSON.json")
names(dataJSON)

str(dataJSON)

dataJSON$menu$popup
```

## Leer Archivos SQL
```{marginfigure}
La historia de MySQL es una llena de ventas y adquisiciones, algo inusual para el Open Software. El motor de la base de datos fue inicialmente desarrollado por MySQL AB (empresa fundada por David Axmark, Allan Larsson y Michael Widenius). MySQL AB fue adquirida por Sun Microsystems en 2008, y ésta a su vez fue comprada por Oracle Corporation en 2010, la cual ya era dueña desde 2005 de Innobase Oy, empresa finlandesa desarrolladora del motor InnoDB para MySQL.
```

MySQL es un sistema de gestión de bases de datos relacional desarrollado bajo licencia dual: Licencia pública general/Licencia comercial por Oracle Corporation y está considerada como la base datos de código abierto más popular del mundo, y una de las más populares en general junto a Oracle y Microsoft SQL Server, sobre todo para entornos de desarrollo web [@MySQL]. 

La estructura de una base de datos MySQL está dividida en:

* bases de datos
* tablas que componen las bases de datos
* campos que componen las tablas

En el lenguaje de MySQL las líneas de un archivo de llaman registros. 

No es la intención de este libro explicar como se maneja MySQL, porque inclusive el más pequeño de los tutoriales pudiera ocupar un capítulo por si solo. Por esa razón solo nos concentraremos en las funciones y librerías de _R_ necesarios para manejar y leer archivos en MySQL. Asumimos que el lector es proficiente en manejar `queries` en SQL para comprender los siguientes pasos. 

La librería externa para manejar bases de datos MySQL en el lenguaje _R_ es `RMySQL`. A diferencia de otras librerías donde la data se lee en una estructura del lenguaje, posiblemente una lista o un _data frame_, la librería de MySQL tiene opciones muy básicas para inyectar comandos de SQL directamente a la misma. Si se cuentan con las credenciales necesarias, es posible abrir una conección a la base de datos, emitir un _query_, y luego cerrar la conexión, todo con un mínimo de comandos en _R_ y algo de comandos nativos en SQL.  

```{marginfigure}
NOTA DE ETICA DE INVESTIGACION: Siempre se debe ser respetuoso de las bases de datos públicas, sobre todo las bases de datos académicas, y no abusar con la lectura innecesaria de datos o las conexiones abiertas. Como científicos debemos utilizar los accesos públicos con responsabilidad, y cerrar todas las conexiones que dejemos abiertas tan pronto se finalice la sesión de investigación.
```

El siguiente ejemplo lee de la base de datos de genomas de la Universidad de California, Santa Cruz, y extrae una lista de las tablas que figuran actualmente [@leek].

```{r readUCSC, warning=FALSE, message=FALSE, cache=TRUE}
library(RMySQL)
ucscDB <- dbConnect(MySQL(), user = "genome", 
      host = "genome-mysql.cse.ucsc.edu")
basesDatos <- dbGetQuery(ucscDB, "show databases")
head(basesDatos)
dbDisconnect(ucscDB)
```

Varias cosas están pasando en el _script_ anterior, más o menos emocionantes dependiendo de la experiencia del científico con bases de datos relacionales. 

* La primera línea del código instala en memoria la librería externa `RMySQL`
* La segunda línea abre una conexión a la base de datos de genomas de UCSC utilizando el usuario y anfitrión (_host_) de acceso público.
* La tercera línea guarda en la variable `basesDatos` los resultados que arroja la función `dbGetQuery(ucscDB, "show databases")`. Esta función utiliza dos parámetros. El primero es la base de datos con la que se abrió la conexión, y el segundo es el comando _SQL_ que se desea ejecutar. En el fondo la función es muy útil pero no deja de ser un simple interface para correr _queries_ de _SQL_ en _R_.
* La quinta línea cierra la conexión con la base de datos. 

Probablemente sepamos a ciencia cierta que base de datos queremos acceder, y podemos entonces especificar una base de datos y conseguir todas sus tablas asociadas. 

```{r readUCSC2, warning=FALSE, message=FALSE, cache=TRUE}
library(RMySQL)
ucscDB_hg19 <- dbConnect(MySQL(), user = "genome", db = "hg19",
      host = "genome-mysql.cse.ucsc.edu")
tablas_hg19 <- dbListTables(ucscDB_hg19)
tablas_hg19[1:5]
dbDisconnect(ucscDB_hg19)
```

Lo mismo aplica con la manipulación de cualquier base de datos. La forma de ejecutar un _query_ es construir una conexión con la base de datos, crear un _query_ como un objeto y utilizar la función `fetch()` para recuperar el resultado del _query_ en una variable. Se pueden desocupar los resultados del _query_ con la función `dbClearResult()` o sencillamente finalizar la conexión. El ejemplo siguiente utiliza una de las tablas de la base de datos `hg19` del mismo juego para analizar la distribución de desajustes [@leek]. 

```{marginfigure}
NOTA: dado que estamos pasando como objetos _strings_ completos con código _SQL_ es importante no equivocarse y pasar por error intentos de borrar, agregar o unir tablas sin una muy buena razón.
```

```{r readUCSC3, warning=FALSE, message=FALSE, cache=TRUE}
library(RMySQL)
library(ggplot2)
ucscDB_hg19 <- dbConnect(MySQL(), user = "genome", db = "hg19",
      host = "genome-mysql.cse.ucsc.edu")

query <- dbSendQuery(ucscDB_hg19, "select * from affyU133Plus2 where
                     misMatches between 1 and 3")

affydata <- fetch(query)
qplot(affydata$nCount, affydata$misMatches) + geom_jitter(alpha=0.5)
dbDisconnect(ucscDB_hg19)
```

